How Surge Pricing Works

The Flow
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SURGE PRICING FLOW                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                         â”‚
â”‚  1. RIDER REQUESTS FARE ESTIMATE                                                        â”‚
â”‚     â””â”€â†’ Rider app calls /api/rides/estimate                                           â”‚
â”‚                                                                 â”‚
â”‚  2. SERVER CALCULATES FARE                                      â”‚
â”‚     â””â”€â†’ calculateFare() in server/index.js                      â”‚
â”‚     â””â”€â†’ Calls calculateSurgeMultiplier(lat, lng)                â”‚
â”‚                                                                 â”‚
â”‚  3. TRY ML FIRST                                                â”‚
â”‚     â””â”€â†’ ml-client.js sends POST to ML API                       â”‚
â”‚     â””â”€â†’ ML API analyzes conditions                              â”‚
â”‚     â””â”€â†’ Returns: { multiplier: 1.8, confidence: 0.85 }          â”‚
â”‚                                                                 â”‚
â”‚  4. IF ML CONFIDENT (â‰¥70%) â†’ USE ML RESULT                      â”‚
â”‚     â””â”€â†’ Surge = 1.8x                                            â”‚
â”‚                                                                 â”‚
â”‚  5. IF ML UNAVAILABLE OR LOW CONFIDENCE â†’ USE RULES             â”‚
â”‚     â””â”€â†’ Check time rules (rush hour, late night)                â”‚
â”‚     â””â”€â†’ Check zone rules (airport, downtown)                    â”‚
â”‚     â””â”€â†’ Check supply/demand ratio                               â”‚
â”‚                                                                 â”‚
â”‚  6. APPLY SURGE TO FARE                                         â”‚
â”‚     â””â”€â†’ Base fare: $15.00                                       â”‚
â”‚     â””â”€â†’ Surge 1.8x: $15.00 Ã— 1.8 = $27.00                       â”‚
â”‚                                                                 â”‚
â”‚  7. RETURN TO RIDER                                             â”‚
â”‚     â””â”€â†’ Shows: "$27.00 (1.8x surge)"                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

What Triggers Surge?
FactorExampleImpactLow Supply3 drivers, 15 ride requestsUp to 3xRush Hour7-9 AM, 5-7 PM weekdays+0.3x to +0.5xLate Night10 PM - 4 AM+0.2x to +0.3xBad WeatherRain, snow, storm+0.3x to +1.0xHeavy Traffic30+ min delays+0.3x to +0.8xAirport ZoneXNA, IAD, DCAZone-specific multiplierSpecial EventsConcert, gameManual override

ML vs Rules
AspectML PredictionRule-BasedData SourceTrained model with patternsDatabase config tablesFactorsWeather, traffic, supply/demand, time, zoneTime rules, zone rulesAccuracyLearns from historical dataStatic thresholdsWhen UsedConfidence â‰¥ 70%ML unavailable or low confidence

Example Scenarios
Scenario 1: Normal Day
Time: 2 PM Tuesday
Weather: Clear
Drivers: 10 available
Requests: 5 pending
â†’ ML predicts: 1.0x (no surge)
â†’ Rider pays base fare
Scenario 2: Rush Hour + Rain
Time: 5:30 PM Friday
Weather: Rain
Drivers: 4 available
Requests: 20 pending
â†’ ML predicts: 2.1x (high confidence)
â†’ Components:
Â   - Demand: 1.4x (low supply)
Â   - Weather: 1.3x (rain)
Â   - Time: 1.15x (rush hour)
â†’ Rider pays 2.1x base fare
Scenario 3: ML Down
ML API unreachable
â†’ Falls back to database rules:
Â   - Rush hour rule: +0.4x
Â   - Zone rule (downtown): +0.2x
â†’ Total: 1.6x surge

Surge Limits
SettingValueMinimum1.0x (never below base)Maximum5.0x (capped)Confidence threshold70%

Where It's Called

Fare Estimate (/api/rides/estimate) - Shows rider expected price
Ride Request (/api/rides/request) - Calculates actual charge
Debug Endpoint (/api/surge/debug) - Testing surge at location




================================================================================

#!/usr/bin/env python3
"""
Pi Rideshare ML API Server
Flask API that exposes ML models for the Node.js backend
"""

import os
import sys
import logging
from pathlib import Path

# Fix import paths - add ml directory to Python path
ML_DIR = Path(__file__).parent
if str(ML_DIR) not in sys.path:
Â    sys.path.insert(0, str(ML_DIR))

from flask import Flask, request, jsonify
from flask_cors import CORS
from datetime import datetime
from functools import wraps

# Now import ML algorithms with fixed paths
from algorithms.surge_pricing import DynamicSurgePricingModel

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

ML_API_KEY = os.environ.get('ML_API_KEY', 'pi-rideshare-ml-key-2025')

# Initialize ML models
surge_model = DynamicSurgePricingModel()

def require_api_key(f):
Â    @wraps(f)
Â    def decorated(*args, **kwargs):
Â        api_key = request.headers.get('X-API-Key')
Â        if api_key != ML_API_KEY:
Â            return jsonify({'error': 'Invalid API key'}), 401
Â        return f(*args, **kwargs)
Â    return decorated

@app.route('/health', methods=['GET'])
def health_check():
Â    return jsonify({
Â        'status': 'healthy',
Â        'service': 'Pi Rideshare ML API',
Â        'timestamp': datetime.now().isoformat(),
Â        'models': {'surge_pricing': surge_model.is_trained}
Â    })

@app.route('/api/ml/surge', methods=['POST'])
@require_api_key
def predict_surge():
Â    try:
Â        data = request.get_json() or {}
Â        zone = data.get('zone', 'default')
Â        conditions = data.get('conditions', {})
Â 
Â        if 'active_drivers' in conditions and 'pending_requests' in conditions:
Â            drivers = conditions['active_drivers'] or 1
Â            requests_count = conditions['pending_requests'] or 1
Â            conditions['supply_demand_ratio'] = drivers / requests_count
Â 
Â        surge_result = surge_model.calculate_surge_multiplier(zone, conditions)
Â 
Â        return jsonify({
Â            'success': True,
Â            'zone': surge_result.zone,
Â            'multiplier': round(surge_result.final_multiplier, 2),
Â            'confidence': round(surge_result.confidence_score, 2),
Â            'components': {
Â                'base': surge_result.base_multiplier,
Â                'weather': round(surge_result.weather_multiplier, 2),
Â                'traffic': round(surge_result.traffic_multiplier, 2),
Â                'demand': round(surge_result.demand_multiplier, 2)
Â            },
Â            'reasoning': surge_result.reasoning,
Â            'timestamp': surge_result.timestamp.isoformat()
Â        })
Â    except Exception as e:
Â        logger.error(f"Surge prediction error: {e}")
Â        return jsonify({
Â            'success': False,
Â            'error': str(e),
Â            'multiplier': 1.0,
Â            'confidence': 0.0
Â        }), 500

if __name__ == '__main__':
Â    port = int(os.environ.get('ML_API_PORT', 5001))
Â    logger.info(f"ðŸš€ Starting ML API Server on port {port}")
Â    app.run(host='0.0.0.0', port=port, debug=False)

======================================================================================================

++++++++++++++++++++++++++++++++++Simplified+++++++++++++++++++++++++++++++++++++++++

#!/usr/bin/env python3
"""
Pi Rideshare ML API Server - Simplified
"""

import os
import logging
from flask import Flask, request, jsonify
from flask_cors import CORS
from datetime import datetime
from functools import wraps

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

ML_API_KEY = os.environ.get('ML_API_KEY', 'pi-rideshare-ml-key-2025')

def require_api_key(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        api_key = request.headers.get('X-API-Key')
        if api_key != ML_API_KEY:
            return jsonify({'error': 'Invalid API key'}), 401
        return f(*args, **kwargs)
    return decorated

def calculate_surge(zone, conditions):
    """Simple surge calculation without ML model"""
    now = datetime.now()
    hour = now.hour
    
    base = 1.0
    
    # Time-based surge
    if hour in [7, 8, 9, 17, 18, 19]:
        base += 0.4
        reasoning = "Rush hour"
    elif hour >= 22 or hour <= 4:
        base += 0.2
        reasoning = "Late night"
    else:
        reasoning = "Normal conditions"
    
    # Weather impact
    weather = conditions.get('weather_condition', 'clear')
    weather_mult = {'clear': 1.0, 'cloudy': 1.1, 'rain': 1.3, 'snow': 1.8, 'storm': 2.0}
    weather_factor = weather_mult.get(weather, 1.0)
    
    # Traffic impact
    traffic_delay = conditions.get('traffic_delay_minutes', 0)
    traffic_factor = 1.0 + min(traffic_delay / 60, 0.8)
    
    # Supply/demand
    drivers = conditions.get('active_drivers', 1) or 1
    requests = conditions.get('pending_requests', 1) or 1
    demand_factor = min(requests / drivers, 3.0) if drivers > 0 else 1.5
    
    final = base * weather_factor * traffic_factor * (0.7 + 0.3 * demand_factor)
    final = max(1.0, min(5.0, final))
    
    return {
        'multiplier': round(final, 2),
        'confidence': 0.75,
        'base': base,
        'weather': round(weather_factor, 2),
        'traffic': round(traffic_factor, 2),
        'demand': round(demand_factor, 2),
        'reasoning': reasoning
    }

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'healthy',
        'service': 'Pi Rideshare ML API',
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/ml/surge', methods=['POST'])
@require_api_key
def predict_surge():
    try:
        data = request.get_json() or {}
        zone = data.get('zone', 'default')
        conditions = data.get('conditions', {})
        
        result = calculate_surge(zone, conditions)
        
        return jsonify({
            'success': True,
            'zone': zone,
            'multiplier': result['multiplier'],
            'confidence': result['confidence'],
            'components': {
                'base': result['base'],
                'weather': result['weather'],
                'traffic': result['traffic'],
                'demand': result['demand']
            },
            'reasoning': result['reasoning'],
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"Surge error: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'multiplier': 1.0,
            'confidence': 0.0
        }), 500

if __name__ == '__main__':
    port = int(os.environ.get('ML_API_PORT', 5001))
    app.run(host='0.0.0.0', port=port, debug=False)